### 主从复制工作流程

+ **建立连接阶段工作流程**

  + ![image-20200826214121916](C:\Users\星星\AppData\Roaming\Typora\typora-user-images\image-20200826214121916.png)

  + 主从连接（slave连接master）

    ```
    方式一：客户端发送命令
    slaveof <masterip> <masterport>
    
    方式二：启动服务器参数
    redis-server -slaveof <masterip> <masterport>
    
    方式三：服务器配置
    slaveof <masterip> <masterport>
    ```

  + 授权访问

    ```
    #master设置密码 （没有启动）
    requirepass <password>
    
    #master配置文件设置密码（已经启动）
    config set requirepass <password>
    config get requirepass
    *********************************************
    #slave配置文件设置密码连接master
    masterauth <password>
    
    #slave启动服务器设置密码连接master
    redis-server –a <password>
    ```

+ **数据同步阶段工作流程**

  + ![image-20200827213814840](C:\Users\星星\AppData\Roaming\Typora\typora-user-images\image-20200827213814840.png)

  + 数据同步阶段master说明
    1. 如果master数据量巨大，数据同步阶段应避开流量高峰期，避免造成master阻塞，影响业务正常执行
    2. 复制缓冲区大小设定不合理，会导致数据溢出。如进行全量复制周期太长，进行部分复制时发现数据已经存在丢失的情况，必须进行第二次全量复制，致使slave陷入死循环状态。`repl-backlog-size 1mb`
    3. master单机内存占用主机内存的比例不应过大，建议使用50%-70%的内存，留下30%-50%的内存用于执行bgsave命令和创建复制缓冲区（复制缓冲区：就是在没有写入到磁盘的数据，还在内存里存着）
  + 数据同步阶段slave说明
    1. 为避免slave进行全量复制、部分复制时服务器响应阻塞或数据不同步，建议关闭此期间的对外服务`slave-serve-stale-data yes|no`
    2. 多个slave同时对master请求数据同步，master发送的RDB文件增多，会对带宽造成巨大冲击，如果master带宽不足，因此数据同步需要根据业务需求，适量错峰
    3. slave过多时，建议调整拓扑结构，由一主多从结构变为树状结构，中间的节点既是master，也是slave。注意使用树状结构时，由于层级深度，导致深度越高的slave与最顶层master间数据同步延迟较大，数据一致性变差，应谨慎选择

+ **心跳机制**

  1. master心跳

     ```
     指令：PING
     周期：由repl-ping-slave-period决定，默认10秒 
     作用：判断slave是否在线
     查询：INFO replication 获取slave最后一次连接时间间隔，lag项维持在0或1视为正常
     ```

  2. slave心跳

     ```
     指令：REPLCONF ACK {offset}
     周期：1秒
     作用1：汇报slave自己的复制偏移量，获取最新的数据变更指令
     作用2：判断master是否在线
     ```

+ **主从复制工作流程（完整）**

  ![image-20200827222259052](C:\Users\星星\AppData\Roaming\Typora\typora-user-images\image-20200827222259052.png)

+ **主从复制常见问题**

  1. 频繁的全量复制

     ```
     问题现象：
     	网络环境不佳，出现网络中断，slave不提供服务
     问题原因：
     	复制缓冲区过小，断网后slave的offset越界，触发全量复制
     最终结果：
     	slave反复进行全量复制
     解决方案：
     	修改复制缓冲区大小 repl-backlog-size
     建议设置如下：
     	1. 测算从master到slave的重连平均时长second
     	2. 获取master平均每秒产生写命令数据总量write_size_per_second
     	3. 最优复制缓冲区空间 = 2 * second * write_size_per_second
     ```

  2. 频繁的网络中断

     ```
     一、
         问题现象： 
             master的CPU占用过高 或 slave频繁断开连接
         问题原因：
             1.slave每1秒发送REPLCONF ACK命令到master 
             2.当slave接到了慢查询时（keys * ，hgetall等），会大量占用CPU性能
             3.master每1秒调用复制定时函数replicationCron()，比对slave发现长时间没有进行响应
         最终结果：
             master各种资源（输出缓冲区、带宽、连接等）被严重占用
         解决方案：
             通过设置合理的超时时间，确认是否释放slave
             repl-timeout【该参数定义了超时时间的阈值（默认60秒），超过该值，释放slave】
     二、
     	问题现象：
     		slave与master连接断开
     	问题原因
             1.master发送ping指令频度较低
     		2.master设定超时时间较短
     		3.ping指令在网络中存在丢包
     	解决方案
     		提高ping指令发送的频度
     		超时时间repl-time的时间至少是ping指令频度的5到10倍，否则slave很容易判定超时
     ```

  3. 数据不一致

     ```
     问题现象
        多个slave获取相同数据不同步
     问题原因
        网络信息不同步，数据发送有延迟
     解决方案
        优化主从间的网络环境，通常放置在同一个机房部署，如使用阿里云等云服务器时要注意此现象
        监控主从节点延迟（通过offset）判断，如果slave延迟过大，暂时屏蔽程序对该slave的数据访问
        slave-serve-stale-data yes|no【开启后仅响应info、slaveof等少数命令（慎用，除非对数据一致性要求很高）】
     ```

